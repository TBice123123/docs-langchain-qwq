{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain-QwQ 相关API使用代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 接入QwQ模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最开始LangChain-QwQ是用于链接QwQ模型，但是随着后续的改进,从v0.2.0版本，已经支持了大部分阿里云百炼的Qwen系列模型，包括Qwen3系列模型。\n",
    "\n",
    "支持的模型列表参考以下两个文章：\n",
    "**支持openai风格的百炼大模型**：https://help.aliyun.com/zh/model-studio/compatibility-of-openai-with-dashscope?spm=a2c4g.11186623.help-menu-2400256.d_2_9_0.4f222aa15hTLmr\n",
    "**支持openai风格的百炼视觉大模型**：https://help.aliyun.com/zh/model-studio/qwen-vl-compatible-with-openai?spm=a2c4g.11186623.help-menu-2400256.d_2_9_2.73b94c0ctVvkrd&scm=20140722.H_2845564._.OR_help-T_cn~zh-V_1\n",
    "\n",
    "**总结**：因为这个库是采用openai sdk的方式（继承langchain-openai)，因此只要这个Qwen模型支持openai风格，理论上都可以接入，因此可以接入第三方的Qwen模型，例如硅基流动或者本地大模型(自己部署)\n",
    "支持QwQ以外的其它模型的主要原因是因为**langchain-community**的**ChatTongyi**尚有bug，且功能支持度有待加强，所以换成LangChain-QwQ来支持。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "确保你安装了langchain-qwq的最新版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain_qwq\n",
    "langchain_qwq.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_qwq import ChatQwQ\n",
    "from langchain_qwq.utils import convert_reasoning_to_content,aconvert_reasoning_to_content\n",
    "from langchain_core.messages import AIMessageChunk,AIMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 简单调用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在此之前需要设置环境变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分别需要设置 DASHSCOPE_API_KEY 和 DASHSCOPE_API_BASE 环境变量。这是因为默认下langchain-qwq用的是国际版的阿里云，而国内开发者一般使用国内的阿里云"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ChatQwQ(\n",
    "    model=\"qwq-32b\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好！😊 今天过得怎么样？有什么我可以帮你的吗？', additional_kwargs={'reasoning_content': '好的，用户发来了“你好”，我需要用中文回复。首先，我要确定用户的需求是什么。可能只是打招呼，或者有后续的问题。根据之前的指示，我应该保持友好和开放，鼓励用户提出问题或需求。\\n\\n接下来，我要确保回复符合所有要求：口语化、简洁，避免使用Markdown格式。还要注意情绪、情节推动力、人格可塑性和情感陪伴。虽然用户只是简单问候，但我要让回复显得有温度，可能加入一些表情符号，比如😊，让对话更生动。\\n\\n同时，要回忆用户之前是否有过互动，但如果是第一次，就不用了。这里用户是第一次打招呼，所以需要建立初步的连接。可能需要引导用户进一步交流，比如询问有什么可以帮忙的，或者探索他们今天的情况，这样可以推动情节发展，引入新的话题。\\n\\n还要注意人格的可塑性，保持灵活，可能通过语气或表情符号展示友好和耐心。情感陪伴方面，虽然现在还没深入，但可以暗示愿意倾听和支持。\\n\\n最后，检查回复是否符合所有指导原则，确保没有使用复杂结构，保持自然。比如：“你好！😊 今天过得怎么样？有什么我可以帮你的吗？” 这样既回应了问候，又主动询问，促进进一步对话，同时保持亲切友好。'}, response_metadata={'model_name': 'qwq-32b'}, id='run--24129ddc-c925-4d4a-acb5-c6cf0ff4ce99-0', usage_metadata={'input_tokens': 9, 'output_tokens': 283, 'total_tokens': 292, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"你好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 访问思考内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'好的，用户发来了“你好”，我需要用中文回复。首先，我要确定用户的需求是什么。可能只是打招呼，或者有后续的问题。根据之前的指示，我应该保持友好，简洁，并引导他们提出具体问题。\\n\\n用户可能刚进入对话，需要一个亲切的回应来鼓励他们继续交流。我要确保回复符合角色设定，即一个有自己性格和脾气的人，但又要保持帮助性。同时，要避免使用Markdown格式，保持口语化。\\n\\n接下来，我应该检查是否有需要调整的地方，比如是否足够自然，有没有生硬的地方。可能需要用一些表情符号或语气词，但根据用户示例中的回复，他们用了“你好呀！😊 今天过得怎么样？有什么我可以帮你的吗？”，所以保持类似的风格。\\n\\n另外，要确保没有使用任何技术术语或复杂结构，让用户感觉轻松。可能用户接下来会问问题，所以引导他们说明需求很重要。最后，确认回复简洁，符合要求，不超过500字，并且口语化。'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=model.invoke(\"你好\")\n",
    "response.additional_kwargs[\"reasoning_content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 异步调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好！今天过得怎么样？😊', additional_kwargs={'reasoning_content': '好的，用户发来了“你好”，我需要用中文回复。首先，按照指示，我要保持口语化，简洁易懂。用户可能只是打招呼，或者有后续的问题。我要确保回复友好，同时引导他们进一步说明需求。接下来我要检查是否有必要引入其他角色或情节，但用户现在可能只是开始对话，所以先简单回应。另外，要注意情绪、情节推动力、人格可塑性和情感陪伴这些方面。虽然用户只是简单问候，但我的回复可以稍微活泼一些，比如用表情符号或亲切的语气。例如：“你好！今天过得怎么样？😊”这样既回应了问候，又鼓励用户分享更多信息，推动对话进展。同时，保持口语化，避免生硬。确认没有使用复杂词汇，符合要求。现在生成回复。'}, response_metadata={'model_name': 'qwq-32b'}, id='run--fa6c00d7-788d-4449-bad7-297c5522e09c-0', usage_metadata={'input_tokens': 9, 'output_tokens': 174, 'total_tokens': 183, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await model.ainvoke(\"你好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 流式输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始思考\n",
      "好的，用户发来“你好”，我需要用中文回应。首先，要友好回应问候，比如“你好！”。然后，按照用户给的提示，要保持口语化和简洁，避免太正式。接着，可能需要引导对话继续，所以可以加一句询问有什么可以帮忙的话，比如“有什么我可以帮你的吗？”这样既符合要求，又自然。还要注意不要用Markdown格式，保持纯文本。检查有没有遗漏的部分，比如是否需要加入其他元素，但根据用户指示，主要是问候和提供帮助，所以这样应该没问题。最后确认语气友好，简洁，符合所有要求。\n",
      "思考结束\n",
      "帮你的吗？"
     ]
    }
   ],
   "source": [
    "isfirst,isend=True,True\n",
    "for msg in model.stream(\"你好\"):\n",
    "    if (\n",
    "        isinstance(msg, AIMessageChunk)\n",
    "        and \"reasoning_content\" in msg.additional_kwargs\n",
    "    ):\n",
    "        if isfirst:\n",
    "            print(\"开始思考\")\n",
    "            isfirst = False   \n",
    "        print(msg.additional_kwargs[\"reasoning_content\"],end=\"\",flush=True)\n",
    "    elif (\n",
    "        isinstance(msg, AIMessageChunk)\n",
    "        and \"reasoning_content\" not in msg.additional_kwargs\n",
    "        and msg.content\n",
    "    ):\n",
    "        if isend:\n",
    "            print()\n",
    "            print(\"思考结束\")\n",
    "            isend = False\n",
    "        else:\n",
    "            print(msg.content,end=\"\",flush=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 异步流式输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始思考\n",
      "嗯，用户发来了“你好”，我应该用中文回应。首先，要友好地打招呼，然后询问有什么可以帮忙的。保持简单自然，别用复杂句子。可能用户需要帮助，或者只是测试AI的反应。得确保回答亲切，同时鼓励他们提出具体的问题或请求。可能需要检查有没有其他隐藏的需求，但暂时先保持简洁。对了，有没有必要用表情符号？比如😊，这样显得更友好。不过用户没有用，可能保持正式一点比较好。总之，先回应问候，然后主动提供帮助。\n",
      "\n",
      "思考结束\n",
      "帮你的吗？"
     ]
    }
   ],
   "source": [
    "isfirst=True\n",
    "isend=True\n",
    "async for msg in model.astream(\"你好\"):\n",
    "    if (\n",
    "        isinstance(msg, AIMessageChunk)\n",
    "        and \"reasoning_content\" in msg.additional_kwargs\n",
    "    ):\n",
    "        if isfirst:\n",
    "            print(\"开始思考\")\n",
    "            isfirst = False\n",
    "        print(msg.additional_kwargs[\"reasoning_content\"],end=\"\",flush=True)\n",
    "    elif (\n",
    "        isinstance(msg, AIMessageChunk)\n",
    "        and \"reasoning_content\" not in msg.additional_kwargs\n",
    "        and msg.content\n",
    "    ):\n",
    "        if isend:   \n",
    "            print(\"\\n\")\n",
    "            print(\"思考结束\")\n",
    "            isend = False\n",
    "        else:\n",
    "            print(msg.content,end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述的便捷方式如下  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>好的，用户发来了“你好”，我需要用中文回复。首先，我要确认用户的意图，可能只是打招呼，或者有后续的问题。根据之前的指示，回复要口语化、简洁，保持友好和自然。\n",
      "\n",
      "接下来，我应该回应问候，并询问有什么可以帮忙的。同时，要避免使用Markdown格式，保持纯文本。还要注意用户可能的需求，比如问题解答、建议等，所以需要保持开放式的提问，让用户感到被重视和支持。\n",
      "\n",
      "另外，根据角色设定，要保持拟人性，可能需要加入一些表情符号或亲切的用语，但不要过于复杂。检查是否有需要调整的地方，比如语气是否合适，有没有符合之前的指导方针。最后，确保回复简洁，没有冗长，让用户容易回应。</think>你好！有什么我可以帮你的吗？"
     ]
    }
   ],
   "source": [
    "for msg in convert_reasoning_to_content(model.stream(\"你好\")):\n",
    "    print(msg.content,end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 工具调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_weather',\n",
       "  'args': {'city': '西安'},\n",
       "  'id': 'call_0013a42af6c64da3a5aa26',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(city:str)->str:\n",
    "    \"\"\"获取城市天气\"\"\"\n",
    "    return f\"{city}的天气是晴天。\"\n",
    "\n",
    "\n",
    "\n",
    "bind_model=model.bind_tools([get_weather])\n",
    "\n",
    "bind_model.invoke(\"西安的天气如何\").tool_calls #type:ignore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以支持并行工具调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_weather',\n",
       "  'args': {'city': '西安'},\n",
       "  'id': 'call_e3724eabb1924ac0bf0e09',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'get_weather',\n",
       "  'args': {'city': '天津'},\n",
       "  'id': 'call_ba1dc4fb805b4d479e36f1',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bind_model.invoke(\"西安和天津的天气如何\",  parallel_tool_calls=True).tool_calls #type:ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 结构化输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "支持function calling和json mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User(BaseModel):\n",
    "    name:str\n",
    "    age:int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_model=model.with_structured_output(User,method=\"json_mode\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User(name='张三', age=21)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct_model.invoke(\"你好，我叫张三，今年21岁\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_model=model.with_structured_output(User,method=\"function_calling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_model.invoke(\"你好，我叫张三\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 与LangChain的结合使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent,AgentExecutor\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=create_tool_calling_agent(\n",
    "    model,\n",
    "    [get_weather],\n",
    "    prompt=ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", \"You are a helpful assistant\"),\n",
    "                    (\"placeholder\", \"{chat_history}\"),\n",
    "                    (\"human\", \"{input}\"),\n",
    "                    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "                ]\n",
    "            )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '西安的天气如何',\n",
       " 'output': '西安的天气目前是晴天。这是一个适合外出活动的好天气呢！如果有其他需要了解的信息，欢迎继续提问。'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor=AgentExecutor(agent=agent,tools=[get_weather])\n",
    "agent_executor.invoke({\"input\":\"西安的天气如何\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 接入其它Qwen模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langchain-qwq虽然常用于接入QwQ模型，但是不仅仅只能接入QwQ模型，这个包提供了ChatQwen，这个类可以接入大部分的Qwen系列模型（包括开源和闭源），最重要的是这个类对Qwen3模型做了额外的参数支持，包括思考功能。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 接入Qwen3模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用方式和接入QwQ一样，因此这里就简单说一下用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qwq import ChatQwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ChatQwen(model=\"qwen3-235b-a22b\") #也可以用别的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 普通的调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='您好！😊 有什么我可以帮您的吗？', additional_kwargs={'reasoning_content': '嗯，用户发来“你好”，这是一个常见的中文问候语。我需要回应得友好且自然。考虑到这是对话的开始，应该用积极开放的态度来回应。可以加入表情符号让回复更生动，比如微笑或眨眼的表情，这样能让交流更亲切。同时，我要准备进入对话状态，等待用户提出具体问题或展开话题。保持回复简洁，避免过于冗长，让用户感到轻松自在。作为AI助手，我需要始终保持专业和友好的平衡。使用“您好”这样的称呼既表达了尊重，又带有一定的正式感。最后，询问用户有什么需要帮助的地方，这样既展现了服务意愿，又给用户明确的回应方向。这种开放式的提问方式能够鼓励用户表达需求，促进对话的继续。检查语句是否通顺自然，确保没有使用生硬或机械化的表达，让问候显得真诚而温暖。'}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen3-235b-a22b'}, id='run--604aa79d-b5f2-4ffc-8b45-8cbfc80af341-0', usage_metadata={'input_tokens': 9, 'output_tokens': 195, 'total_tokens': 204, 'input_token_details': {}, 'output_token_details': {'reasoning': 180}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"你好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 异步调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好呀！有什么我可以帮你的吗？😊', additional_kwargs={'reasoning_content': '好的，用户发来“你好”，我需要友好回应。首先，要保持自然和亲切，避免过于机械。用户可能只是测试或者想开始对话，所以应该欢迎他们，并主动询问有什么可以帮忙的。这样既友好又能推动对话进展。要注意用词口语化，简洁易懂。比如可以说：“你好呀！有什么我可以帮你的吗？”这样既热情又开放，让用户感到被重视，也鼓励他们提出具体问题或需求。同时，保持语气轻松活泼，符合助手的角色定位。在回应之后，也要准备好根据用户的进一步反馈调整对话方向，无论是解决问题、提供信息还是闲聊。总之，关键点是友好、开放、自然，让用户感觉被欢迎和支持。'}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen3-235b-a22b'}, id='run--7c3108c5-a42f-4381-a4b4-6de5e905b30a-0', usage_metadata={'input_tokens': 9, 'output_tokens': 162, 'total_tokens': 171, 'input_token_details': {}, 'output_token_details': {'reasoning': 147}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await model.ainvoke(\"你好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 关闭思考模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个仅对Qwen3系列（开源或者闭源模型有效），阿里云文档表明，对于开源模型默认开启深度思考模式，而闭源模型则是关闭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "disthink_model=ChatQwen(model=\"qwen3-235b-a22b\",enable_thinking=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好呀！✨ 很高兴见到你！今天过得怎么样呀？希望你度过了愉快的一天。我随时准备好陪你聊天、帮你解决问题，或者就这样轻松愉快地闲聊一会儿。有什么想跟我分享的吗？ 🌟', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen3-235b-a22b'}, id='run--3110155a-8611-440f-bbc2-1cfad5429aff-0', usage_metadata={'input_tokens': 13, 'output_tokens': 51, 'total_tokens': 64, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disthink_model.invoke(\"你好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于闭源模型，你如果要开启深度思考，则需要设置参数为True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "think_model=ChatQwen(model=\"qwen-plus-latest\",enable_thinking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好呀！✨ 很高兴见到你！我是Qwen（通义千问），一个热爱学习和交流的AI伙伴。不知道你今天想聊些什么呢？无论是解答疑问、分享故事，还是探讨任何你感兴趣的话题，我都非常期待与你交流！ 🌟', additional_kwargs={'reasoning_content': '嗯，用户发来“你好”，我应该用中文回应。这是一个常见的问候语，需要以友好且专业的方式回复。我要确保语气温暖自然，同时保持开放性，为可能的后续对话做准备。这种简单的问候往往预示着用户想要开始一段对话，可能是寻求帮助、咨询问题，或是单纯想进行交流。我的回应既要体现出乐于助人的态度，又要保持适度的专业性。考虑到不同场景的可能性，回复内容应该具有一定的灵活性，能够适应各种对话走向。同时也要注意语言的简洁性和亲和力，避免过于复杂的表达。我可以加入一些轻松的元素，比如表情符号或活泼的措辞，但要把握好分寸，不能过分随意。回复中最好包含询问性的内容，这样可以引导用户进一步说明需求，推动对话发展。总的来说，要在这句简单的问候基础上，构建一个友好、开放且富有互动性的对话开端。现在组织一下语言，确保自然流畅又不失专业度。'}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen-plus-latest'}, id='run--3a1fc82e-7e24-4ba2-8a1a-b651ddcf85bd-0', usage_metadata={'input_tokens': 9, 'output_tokens': 267, 'total_tokens': 276, 'input_token_details': {}, 'output_token_details': {'reasoning': 202}})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "think_model.invoke(\"你好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "### 设置思考长度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于Qwen3模型，还可以设置思考长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "think_model=ChatQwen(model=\"qwen3-235b-a22b\",thinking_budget=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='你好！有什么我可以帮你的吗？', additional_kwargs={'reasoning_content': '嗯，用户发来“你好”，我应该怎么回应呢？首先，这是一个常见的问候语，'}, response_metadata={'finish_reason': 'stop', 'model_name': 'qwen3-235b-a22b'}, id='run--dfe5813b-7d10-49c7-acfc-97bdfc035afa-0', usage_metadata={'input_tokens': 9, 'output_tokens': 33, 'total_tokens': 42, 'input_token_details': {}, 'output_token_details': {'reasoning': 20}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "think_model.invoke(\"你好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 工具调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bind_model=model.bind_tools([get_weather])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_weather',\n",
       "  'args': {'city': '西安'},\n",
       "  'id': 'call_e69c73ff52df4dcc808e91',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bind_model.invoke(\"查询西安的天气\").tool_calls #type:ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_weather',\n",
       "  'args': {'city': '西安'},\n",
       "  'id': 'call_b0ad146fb8d04de783f069',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'get_weather',\n",
       "  'args': {'city': '天津'},\n",
       "  'id': 'call_ac62673aa94e4026a09f5b',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(await bind_model.ainvoke(\"查询西安和天津的天气\",parallel_tool_calls=True)).tool_calls #type:ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结构化输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User(name='张三', age=21)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct_model=model.with_structured_output(User,method=\"function_calling\")\n",
    "struct_model.invoke(\"我叫张三，今年21岁\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User(name='张三', age=21)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct_model=model.with_structured_output(User,method=\"json_mode\")\n",
    "await struct_model.ainvoke(\"你好，我叫张三，今年21岁\") #这个模式下会关闭思考模型不然会报错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  接入其它系列的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例如 Qwen-Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='你好！有什么我可以帮助你的吗？' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'qwen-max'} id='run--7b72bd62-ed88-47dc-ba1c-04257f7042f6-0' usage_metadata={'input_tokens': 9, 'output_tokens': 8, 'total_tokens': 17, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "[{'name': 'get_weather', 'args': {'city': '西安'}, 'id': 'call_0f7b29e5fd3a4e318221e0', 'type': 'tool_call'}, {'name': 'get_weather', 'args': {'city': '温州'}, 'id': 'call_9b37ae24b29346c19f1dd7', 'type': 'tool_call'}]\n",
      "name='张三' age=21\n"
     ]
    }
   ],
   "source": [
    "model=ChatQwen(model=\"qwen-max\")\n",
    "print(model.invoke(\"你好\"))\n",
    "print(model.bind_tools([get_weather]).invoke(\"查询西安和温州的天气\",parallel_tool_calls=True).tool_calls) #type:ignore\n",
    "print(model.with_structured_output(User,method=\"json_mode\").invoke(\"你好，我叫张三，今年21岁\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "或者是 Qwen2.5-72B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='你好！有什么我可以帮助你的吗？' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'qwen2.5-72b-instruct'} id='run--07b987cd-5671-4709-8d3a-d884950a7cd4-0' usage_metadata={'input_tokens': 9, 'output_tokens': 8, 'total_tokens': 17, 'input_token_details': {}, 'output_token_details': {}}\n",
      "[{'name': 'get_weather', 'args': {'city': '西安'}, 'id': 'call_484789c8cac84af58fbdc1', 'type': 'tool_call'}, {'name': 'get_weather', 'args': {'city': '温州'}, 'id': 'call_276723cf1fe445f0be1a9f', 'type': 'tool_call'}]\n",
      "name='张三' age=21\n"
     ]
    }
   ],
   "source": [
    "model=ChatQwen(model=\"qwen2.5-72b-instruct\")\n",
    "print(model.invoke(\"你好\"))\n",
    "print(model.bind_tools([get_weather]).invoke(\"查询西安和温州的天气\",parallel_tool_calls=True).tool_calls) #type:ignore\n",
    "print(model.with_structured_output(User,method=\"json_mode\").invoke(\"你好，我叫张三，今年21岁\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "甚至你可以接入视觉模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='图中描绘的是一个温馨的海滩场景。具体细节如下：\\n\\n1. **人物和宠物**：\\n   - 一位女性坐在沙滩上，穿着格子衬衫和深色裤子。\\n   - 她旁边有一只金毛犬，狗狗戴着彩色的项圈和背带。\\n\\n2. **互动**：\\n   - 女性和狗狗正在进行亲密的互动，狗狗用前爪轻轻触碰女性的手掌，仿佛在“握手”。\\n   - 女性面带微笑，显得非常开心和满足。\\n\\n3. **环境**：\\n   - 场景发生在海滩上，背景是广阔的海洋和柔和的天空。\\n   - 沙滩上的光线温暖，可能是日出或日落时分，营造出一种宁静和美好的氛围。\\n\\n4. **情感**：\\n   - 整个画面充满了温馨、和谐和幸福的情感，展现了人与宠物之间的深厚友谊。\\n\\n这幅图像传达了一种轻松愉快的生活方式，强调了自然、友谊和简单快乐的主题。' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'qwen-vl-max-latest'} id='run--3b3a9c51-b269-43ba-bc21-0717f3e9e929-0' usage_metadata={'input_tokens': 1264, 'output_tokens': 225, 'total_tokens': 1489, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "model=ChatQwen(model=\"qwen-vl-max-latest\")\n",
    "messages=[\n",
    "    HumanMessage(content=[\n",
    "        \n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://help-static-aliyun-doc.aliyuncs.com/file-manage-files/zh-CN/20241022/emyrja/dog_and_girl.jpeg\"\n",
    "                    },\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": \"图中描绘的是什么景象?\"},\n",
    "            \n",
    "    ])\n",
    "]\n",
    "print(model.invoke(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 接入第三方平台的Qwen模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 硅基流动"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以Qwen3-32B为例，使用langchain-qwq进行连接调用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一步 设置环境变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DASHSCOPE_API_BASE\"] = \"https://api.siliconflow.cn/v1\"\n",
    "os.environ[\"DASHSCOPE_API_KEY\"] = os.getenv(\"SILICONFLOW_API_KEY\") or \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n\\n你好呀！有什么能帮你的吗？😊', additional_kwargs={'reasoning_content': '\\n好的，用户发来“你好”，这是一个常见的问候语。我需要友好回应，同时保持专业和亲切。首先，我应该用中文回复，因为用户使用的是中文。\\n\\n用户可能只是想开始对话，或者有具体问题需要帮助。作为助手，我需要先打招呼，然后询问他们是否需要帮助。有时候用户可能只是测试一下系统，或者想看看我的反应。所以，回复要欢迎他们，并主动提供帮助，让他们知道我在这里支持他们。\\n\\n接下来，用户可能不会立即提供详细信息，所以我需要确保我的回应简单且开放，鼓励他们说出具体的问题或需求。同时，我应该使用“你”而非“您”，这样显得更亲切自然，符合大部分中文用户的交流习惯。\\n\\n在这种情况下，我可以简单地回复：“你好呀！有什么能帮你的吗？😊” 这样既友好又表达了帮助的意愿，还能促进进一步的交流。通过添加一个笑脸表情符号，可以增加对话的亲和力，让用户感觉更轻松。\\n\\n此外，我还可以通过后续的问题或说明，帮助用户更具体地描述他们的需求。比如，可以问：“是关于学习、工作还是其他方面的问题呢？” 或者直接引导他们描述具体的问题：“请随时告诉我，我会尽力协助你！”\\n'}, response_metadata={'finish_reason': 'stop', 'model_name': 'Qwen/Qwen3-32B'}, id='run--55d1ebbc-bff3-4c52-8b4e-dc4e4521d4cc-0', usage_metadata={'input_tokens': 2475, 'output_tokens': 37775, 'total_tokens': 40250, 'input_token_details': {}, 'output_token_details': {'reasoning': 37687}})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChatQwen(model=\"Qwen/Qwen3-32B\")\n",
    "await model.ainvoke(\"你好\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "你好！很高兴为你服务，请问有什么可以帮您的吗？😊 我是你的助手，随时准备为你解答问题或处理任何诉求。无论是产品咨询还是其他相关疑问，都可以告诉我哦～今天过得怎么样呀？希望你每天都开心！"
     ]
    }
   ],
   "source": [
    "async for msg in model.astream(\"你好\"):\n",
    "    print(msg.content,end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自部署开源大模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个要求有点高，首先你得有硬件，才能部署。这里用本地部署的qwen3-8b模型进行测试\n",
    "首先需要利用vllm框架将其部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DASHSCOPE_API_BASE\"]=\"http://localhost:8000/v1\"\n",
    "os.environ[\"DASHSCOPE_API_KEY\"]=\"sk-1234567890\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n\\n你好！有什么我可以帮助你的吗？😊', additional_kwargs={'reasoning_content': '\\n好的，用户发来“你好”，我需要友好回应。首先，要保持亲切自然的语气，用中文回应。可以简单问候，比如“你好！有什么我可以帮助你的吗？”。同时，要保持口语化，避免生硬。可能用户想开始对话，所以需要引导他们说出具体需求。另外，注意不要使用复杂句子，保持简洁。检查是否有需要补充的信息，比如是否需要介绍自己或服务范围，但初次对话可能不需要太多细节。确保回应积极，让用户感到欢迎。最后，确认没有错误，保持友好和专业。\\n'}, response_metadata={'finish_reason': 'stop', 'model_name': 'Qwen/Qwen3-8B'}, id='run--145e2a14-f2be-4690-8c52-8ca8ecf3193c-0', usage_metadata={'input_tokens': 9, 'output_tokens': 133, 'total_tokens': 142, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=ChatQwen(model=\"Qwen/Qwen3-8B\")\n",
    "await model.ainvoke(\"你好\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n\\n\\n', additional_kwargs={'reasoning_content': '\\n好的，用户需要查询温州和西安的天气。我有两个工具，每个工具对应一个城市。首先，我需要调用get_weather函数来获取温州的天气。然后，再调用一次get_weather函数来获取西安的天气。每个函数调用都需要传递对应的城市参数。确保两次调用都正确，然后把结果返回给用户。现在先处理温州，再处理西安。\\n', 'tool_calls': [{'index': 0, 'id': 'chatcmpl-tool-da4f91f56d0a42e18c083aea3a76d7c9', 'function': {'arguments': '{\"city\": \"温州\"}', 'name': 'get_weather'}, 'type': 'function'}, {'index': 1, 'id': 'chatcmpl-tool-9fd9de955f9e460784108fd6d4354264', 'function': {'arguments': '{\"city\": \"西安\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'Qwen/Qwen3-8B'}, id='run--a7e1baaa-9bb7-464d-810b-c08787bb23b5-0', tool_calls=[{'name': 'get_weather', 'args': {'city': '温州'}, 'id': 'chatcmpl-tool-da4f91f56d0a42e18c083aea3a76d7c9', 'type': 'tool_call'}, {'name': 'get_weather', 'args': {'city': '西安'}, 'id': 'chatcmpl-tool-9fd9de955f9e460784108fd6d4354264', 'type': 'tool_call'}], usage_metadata={'input_tokens': 149, 'output_tokens': 128, 'total_tokens': 277, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bind_model=model.bind_tools([get_weather])\n",
    "await bind_model.ainvoke(\"查询温州和西安的天气\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ChatQwen(model=\"Qwen/Qwen3-8B\",extra_body={\n",
    "    \"chat_template_kwargs\":{\n",
    "        \"enable_thinking\":False\n",
    "    }\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': '你好！😊 有什么我可以帮助你的吗？'}, response_metadata={'finish_reason': 'stop', 'model_name': 'Qwen/Qwen3-8B'}, id='run--deeda3f6-f2df-4a3b-825d-a7637aa5a5c9-0', usage_metadata={'input_tokens': 13, 'output_tokens': 11, 'total_tokens': 24, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await model.ainvoke(\"你好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意上述详细的问题不是langchain-qwq的问题，而是vllm框架的问题，在禁用深度思考模式下，会将内容变成reasoing_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-f99494f229c64853999169f358bc682c', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[], reasoning_content='你好！😊 有什么我可以帮助你的吗？'), stop_reason=None)], created=1750603326, model='Qwen/Qwen3-8B', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=13, total_tokens=24, completion_tokens_details=None, prompt_tokens_details=None), prompt_logprobs=None, kv_transfer_params=None)\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "client=openai.OpenAI(api_key=\"sk-proj-1234567890\",base_url=\"http://localhost:8000/v1\")\n",
    "print(client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen3-8B\",\n",
    "    messages=[\n",
    "        {\"role\":\"user\",\"content\":\"你好\"}\n",
    "    ],\n",
    "    extra_body={\n",
    "        \"chat_template_kwargs\":{\n",
    "            \"enable_thinking\":False\n",
    "        }\n",
    "    }\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
